# Projet de Pipeline de Données

Ce pipeline de données a pour objectif de transformer des données brutes provenant de GitHub en informations exploitables. Il utilise Azure Data Factory pour extraire les données de GitHub et les charger dans Azure Data Lake Storage Gen2. Databricks est ensuite utilisé pour nettoyer, transformer et enrichir les données. Enfin, Power BI permet de visualiser les résultats de manière claire et concise. La sécurité des données est assurée par Azure Key Vault (AKV).

## Architecture

![Architecture du projet](https://github.com/Nelly-98/ELT-with-Azure/blob/main/1717506406224.jpeg)


## Objectifs:
* Ingérer des données depuis GitHub
* Transformer les données à l'aide de Databricks
* Stocker les données transformées dans Azure Data Lake Storage Gen2
* Visualiser les données dans Power BI

## Technologies utilisées:
* Azure Data Factory
* Databricks
* Power BI
* Azure Data Lake Storage Gen2
* GitHub
* Azure Key Vault

**Instructions d'utilisation:**
...

## Contributeurs:
* Nelly Guepnang